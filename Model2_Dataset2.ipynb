{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11020543,"sourceType":"datasetVersion","datasetId":6862353}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\n# Load your dataset\nfile_path = \"/kaggle/input/tamil-grammar-dataset/tamil_grammar_large_dataset.csv\"  # Update with your actual file path\ndf = pd.read_csv(file_path)\n\n# Check the first few rows to understand the structure\nprint(df.head())\n\n# Remove rows with any null values in the dataset\ndf_cleaned = df.dropna()\n\n# Remove duplicate rows\ndf_cleaned = df_cleaned.drop_duplicates()\n\n# Optionally, you can reset the index after cleaning\ndf_cleaned = df_cleaned.reset_index(drop=True)\n\n# Check the cleaned dataset\nprint(df_cleaned.head())\n\n# Save the cleaned dataset to a new CSV file\ndf_cleaned.to_csv(\"cleaned_dataset.csv\", index=False)\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-03-13T14:31:59.954580Z","iopub.execute_input":"2025-03-13T14:31:59.954820Z","iopub.status.idle":"2025-03-13T14:32:00.327484Z","shell.execute_reply.started":"2025-03-13T14:31:59.954799Z","shell.execute_reply":"2025-03-13T14:32:00.326790Z"},"trusted":true},"outputs":[{"name":"stdout","text":"                          Sentence              Error Type  \\\n0  அவர்கள் பள்ளிக்கு சாப்பிடுவாள்.          Spelling Error   \n1     நாம் பாடத்தை படிக்கிறார்கள்.  Subject-Verb Agreement   \n2     அவன் பள்ளிக்கு சாப்பிடுவாள்.          Spelling Error   \n3    அவர்கள் பந்து விளையாடுகிறோம்.                No Error   \n4  நான் புத்தகத்தை விளையாடுகிறான்.  Subject-Verb Agreement   \n\n               Corrected Sentence  \n0  அவர்கள் பள்ளிக்கு படிக்கிறாள்.  \n1          நாம் பாடத்தை செல்வேன்.  \n2  அவன் பள்ளிக்கு விளையாடுகிறோம்.  \n3   அவர்கள் பந்து விளையாடுகிறோம்.  \n4    நான் புத்தகத்தை படிக்கிறான்.  \n                          Sentence              Error Type  \\\n0  அவர்கள் பள்ளிக்கு சாப்பிடுவாள்.          Spelling Error   \n1     நாம் பாடத்தை படிக்கிறார்கள்.  Subject-Verb Agreement   \n2     அவன் பள்ளிக்கு சாப்பிடுவாள்.          Spelling Error   \n3    அவர்கள் பந்து விளையாடுகிறோம்.                No Error   \n4  நான் புத்தகத்தை விளையாடுகிறான்.  Subject-Verb Agreement   \n\n               Corrected Sentence  \n0  அவர்கள் பள்ளிக்கு படிக்கிறாள்.  \n1          நாம் பாடத்தை செல்வேன்.  \n2  அவன் பள்ளிக்கு விளையாடுகிறோம்.  \n3   அவர்கள் பந்து விளையாடுகிறோம்.  \n4    நான் புத்தகத்தை படிக்கிறான்.  \n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_MODE\"] = \"disabled\"","metadata":{"execution":{"iopub.status.busy":"2025-03-13T14:32:06.712941Z","iopub.execute_input":"2025-03-13T14:32:06.713270Z","iopub.status.idle":"2025-03-13T14:32:06.717525Z","shell.execute_reply.started":"2025-03-13T14:32:06.713243Z","shell.execute_reply":"2025-03-13T14:32:06.716472Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM,AutoModel\nimport pandas as pd\n\n# Load Tamil-specific model and tokenizer\nmodel_name = \"facebook/nllb-200-distilled-600M\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModel.from_pretrained(model_name)\n\n# Load your cleaned dataset\ndf_cleaned = pd.read_csv(\"cleaned_dataset.csv\")\n\n# Calculate max input and target lengths based on tokenized sentences\nmax_input_length = max([len(tokenizer.encode(sentence, truncation=True, padding=False)) for sentence in df_cleaned['Sentence']])\nmax_target_length = max([len(tokenizer.encode(sentence, truncation=True, padding=False)) for sentence in df_cleaned['Corrected Sentence']])\n\nprint(f\"Max Input Length: {max_input_length}\")\nprint(f\"Max Target Length: {max_target_length}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T14:32:10.517832Z","iopub.execute_input":"2025-03-13T14:32:10.518107Z","iopub.status.idle":"2025-03-13T14:32:46.487862Z","shell.execute_reply.started":"2025-03-13T14:32:10.518088Z","shell.execute_reply":"2025-03-13T14:32:46.486563Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"208a8a9f17a449bca207d5c709400a2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8ae1714076b496a81594554c395b6a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"122e4d757ae346c4acf9c49fdf4310a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2ca836d751040a4911415c51c5d2d86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06f9b3d6c1d9431bb80406a3a6d0f344"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0adfe5f9685b4b0e8042ef88923f7efa"}},"metadata":{}},{"name":"stdout","text":"Max Input Length: 11\nMax Target Length: 10\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Trainer, TrainingArguments\nfrom sklearn.model_selection import train_test_split\nfrom datasets import Dataset\n\n# Load the cleaned dataset\ndf_cleaned = pd.read_csv(\"cleaned_dataset.csv\")\n\n# Split the dataset into training and validation sets\ntrain_df, val_df = train_test_split(df_cleaned, test_size=0.1)\n\n# Convert the dataframe to Hugging Face dataset format\ntrain_dataset = Dataset.from_pandas(train_df)\nval_dataset = Dataset.from_pandas(val_df)\n\n# Load NLLB-200 model and tokenizer\nmodel_name = \"facebook/nllb-200-distilled-600M\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\n# Set the language code for Tamil\ntamil_lang_code = \"tam_Taml\"\n\n# Tokenizer function\ndef preprocess_function(examples):\n    inputs = examples['Sentence']\n    targets = examples['Corrected Sentence']\n\n    # Add language token for Tamil\n    inputs = [f\"{tamil_lang_code} {text}\" for text in inputs]\n    \n    # Tokenize input and target sequences\n    model_inputs = tokenizer(inputs, max_length=11, truncation=True, padding=\"max_length\")\n    labels = tokenizer(targets, max_length=10, truncation=True, padding=\"max_length\")\n\n    # Add the labels to model inputs\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    \n    return model_inputs\n\n# Apply tokenization\ntrain_dataset = train_dataset.map(preprocess_function, batched=True)\nval_dataset = val_dataset.map(preprocess_function, batched=True)\n\n# Set up training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=3e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=5,\n    weight_decay=0.01,\n    save_total_limit=2,\n    logging_dir=\"./logs\",\n    warmup_steps=int(0.1 * len(train_dataset)),\n    lr_scheduler_type=\"linear\",\n    gradient_accumulation_steps=2,\n    max_grad_norm=1.0,\n    run_name=\"tamil-error-correction-nllb200\",\n    report_to=[]\n)\n\n# Create Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=tokenizer\n)\n\n# Train the model\ntrainer.train()\n\n# Save the trained model\ntrainer.save_model(\"trained_model_nllb200\")\n\n# Evaluate the model\nresults = trainer.evaluate(val_dataset)\nprint(results)\n","metadata":{"execution":{"iopub.status.busy":"2025-03-13T14:32:50.019149Z","iopub.execute_input":"2025-03-13T14:32:50.019833Z","iopub.status.idle":"2025-03-13T14:41:02.065107Z","shell.execute_reply.started":"2025-03-13T14:32:50.019723Z","shell.execute_reply":"2025-03-13T14:41:02.064338Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c73a590b158e4f198c38030a7738f17f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1775 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6c44aefd3394cf6a73a4c71469c901c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/198 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cf66f5dd8df40e69352f6c89974bfef"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n<ipython-input-4-ba2effa9a302>:65: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='275' max='275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [275/275 07:46, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>2.606803</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.634597</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>1.188154</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.726022</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [13/13 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.7260220646858215, 'eval_runtime': 3.9216, 'eval_samples_per_second': 50.49, 'eval_steps_per_second': 3.315, 'epoch': 4.918918918918919}\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Extract logs from Trainer state\nlog_history = trainer.state.log_history\n\n# Separate training and validation losses\ntrain_losses = [entry['loss'] for entry in log_history if 'loss' in entry]\neval_losses = [entry['eval_loss'] for entry in log_history if 'eval_loss' in entry]\nlearning_rates = [entry['learning_rate'] for entry in log_history if 'learning_rate' in entry]\n\n# Create x-axis for epochs\n\nepochs_eval = range(1, len(eval_losses) + 1)\n\n\n# Plot validation loss\nplt.figure(figsize=(6, 4))\nplt.plot(epochs_eval, eval_losses, label=\"Validation Loss\", marker='o', color='red')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Validation Loss over Epochs\")\nplt.legend()\nplt.grid()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T14:41:06.836495Z","iopub.execute_input":"2025-03-13T14:41:06.836919Z","iopub.status.idle":"2025-03-13T14:41:07.126966Z","shell.execute_reply.started":"2025-03-13T14:41:06.836883Z","shell.execute_reply":"2025-03-13T14:41:07.126080Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 600x400 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import torch\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom nltk.translate.bleu_score import sentence_bleu\n\n\n# Check if GPU is available and move the model to GPU if it is\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = model.to(device)\n\n# Generate predictions on the validation set\npredictions = []\nreferences = []\n\n# Use the model to generate predictions on the validation set\nfor example in val_dataset:\n    input_ids = tokenizer(example['Sentence'], return_tensors='pt', padding=True, truncation=True, max_length=35).input_ids\n    \n    # Move input_ids to the correct device (same as the model)\n    input_ids = input_ids.to(device)\n    \n    output_ids = model.generate(input_ids)\n    decoded_prediction = tokenizer.decode(output_ids[0], skip_special_tokens=True)  # Use tokenizer's decode method\n\n    predictions.append(decoded_prediction)\n    references.append(example['Corrected Sentence'])\n\n# BLEU Score Calculation (with n-gram overlap)\ndef calculate_bleu(predictions, references):\n    bleu_scores = []\n    for pred, ref in zip(predictions, references):\n        # Tokenize sentences and calculate BLEU score\n        pred_tokens = pred.split()\n        ref_tokens = ref.split()\n        bleu_scores.append(sentence_bleu([ref_tokens], pred_tokens))  # List of references is passed to sentence_bleu\n    return sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0\n\n\n# Calculate BLEU\nbleu_score = calculate_bleu(predictions, references)\n\n\n# Print the results\nprint(f\"BLEU Score: {bleu_score:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-13T14:41:15.635524Z","iopub.execute_input":"2025-03-13T14:41:15.635873Z","iopub.status.idle":"2025-03-13T14:41:45.271445Z","shell.execute_reply.started":"2025-03-13T14:41:15.635844Z","shell.execute_reply":"2025-03-13T14:41:45.270472Z"},"trusted":true},"outputs":[{"name":"stdout","text":"BLEU Score: 0.8265\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 3-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 4-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!pip install bert_score\nfrom bert_score import score\nP, R, F1 = score(predictions, references, lang=\"ta\")  # Adjust the language if necessary (e.g., \"ta\" for Tamil)\n\n# Print BERT scores\nprint(f\"BERT Precision: {P.mean():.4f}\")\nprint(f\"BERT Recall: {R.mean():.4f}\")\nprint(f\"BERT F1 Score: {F1.mean():.4f}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-13T14:41:58.387957Z","iopub.execute_input":"2025-03-13T14:41:58.388296Z","iopub.status.idle":"2025-03-13T14:42:18.237094Z","shell.execute_reply.started":"2025-03-13T14:41:58.388268Z","shell.execute_reply":"2025-03-13T14:42:18.235833Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting bert_score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.5.1+cu121)\nRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.2.3)\nRequirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.47.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert_score) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.32.3)\nRequirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.67.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert_score) (3.7.5)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert_score) (24.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2025.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.29.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.4.5)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.4.7)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (3.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2025.1.31)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->bert_score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->bert_score) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->bert_score) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->bert_score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->bert_score) (2024.2.0)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: bert_score\nSuccessfully installed bert_score-0.3.13\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7becd7f4c80948bb8fac5a144dc9b5f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8280fdd3baa4ef3a9c8b2cfe8b46b92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bec7b5a210094423beb85d8ed8eef346"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b7d108a336943039fec3b4d6abc2243"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abcccac566ec48fd99f77f27956c58e3"}},"metadata":{}},{"name":"stdout","text":"BERT Precision: 0.9354\nBERT Recall: 0.9108\nBERT F1 Score: 0.9226\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import nltk\n\ndef calculate_ter(references, predictions):\n    \"\"\"\n    Compute TER (Translation Edit Rate) score.\n    references: list of reference sentences (the correct sentences)\n    predictions: list of generated sentences (the sentences predicted by the model)\n    \"\"\"\n    # Initialize the TER scores\n    ter_scores = []\n    \n    # Loop over all the sentences\n    for ref, hyp in zip(references, predictions):\n        ref_tokens = ref.split()  # Tokenize the reference sentence\n        hyp_tokens = hyp.split()  # Tokenize the hypothesis sentence\n\n        # Find the minimum edit distance (substitutions, insertions, deletions)\n        edits = nltk.edit_distance(ref_tokens, hyp_tokens)\n\n        # TER is calculated as (number of edits + len(reference) - len(hypothesis)) / len(reference)\n        ter = (edits + len(ref_tokens) - len(hyp_tokens)) / len(ref_tokens)\n        ter_scores.append(ter)\n\n    # Average TER score across all sentences\n    avg_ter = sum(ter_scores) / len(ter_scores) if ter_scores else 0\n    return avg_ter\n\n\n\nter_score = calculate_ter(references, predictions)\nprint(f\"TER Score: {ter_score:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-03-13T14:42:52.273101Z","iopub.execute_input":"2025-03-13T14:42:52.273420Z","iopub.status.idle":"2025-03-13T14:42:52.281906Z","shell.execute_reply.started":"2025-03-13T14:42:52.273395Z","shell.execute_reply":"2025-03-13T14:42:52.281051Z"},"trusted":true},"outputs":[{"name":"stdout","text":"TER Score: 0.2407\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import nltk\nfrom collections import Counter\n\ndef calculate_gleu(references, predictions, max_order=4):\n    \"\"\"\n    Compute GLEU score.\n    references: list of reference sentences (the correct sentences)\n    predictions: list of generated sentences (the sentences predicted by the model)\n    max_order: maximum n-gram length for the BLEU calculation (default is 4)\n    \"\"\"\n    def get_ngrams(tokens, n):\n        return [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n\n    def compute_sentence_gleu(ref_tokens, hyp_tokens):\n        \"\"\"\n        Compute the GLEU score for a single sentence pair.\n        \"\"\"\n        total_ref_ngrams = Counter()\n        total_hyp_ngrams = Counter()\n        total_match_ngrams = Counter()\n\n        for n in range(1, max_order + 1):\n            ref_ngrams = get_ngrams(ref_tokens, n)\n            hyp_ngrams = get_ngrams(hyp_tokens, n)\n            \n            ref_ngrams_count = Counter(ref_ngrams)\n            hyp_ngrams_count = Counter(hyp_ngrams)\n\n            total_ref_ngrams.update(ref_ngrams_count)\n            total_hyp_ngrams.update(hyp_ngrams_count)\n            total_match_ngrams.update(ref_ngrams_count & hyp_ngrams_count)  # Intersection for matching n-grams\n\n        # Compute precision and recall\n        precision = sum(total_match_ngrams.values()) / sum(total_hyp_ngrams.values()) if total_hyp_ngrams else 0\n        recall = sum(total_match_ngrams.values()) / sum(total_ref_ngrams.values()) if total_ref_ngrams else 0\n\n        # Compute GLEU score (harmonic mean of precision and recall)\n        if precision + recall > 0:\n            gleu = (1 + 0.5) * (precision * recall) / (0.5 * precision + recall)\n        else:\n            gleu = 0\n        return gleu\n\n    # Initialize the GLEU scores\n    gleu_scores = []\n\n    # Loop over all reference-prediction pairs\n    for ref, hyp in zip(references, predictions):\n        ref_tokens = ref.split()  # Tokenize the reference sentence\n        hyp_tokens = hyp.split()  # Tokenize the hypothesis sentence\n\n        gleu_score = compute_sentence_gleu(ref_tokens, hyp_tokens)\n        gleu_scores.append(gleu_score)\n\n    # Average GLEU score across all sentences\n    avg_gleu = sum(gleu_scores) / len(gleu_scores) if gleu_scores else 0\n    return avg_gleu\n\ngleu_score = calculate_gleu(references, predictions)\nprint(f\"GLEU Score: {gleu_score:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-03-13T14:43:01.992630Z","iopub.execute_input":"2025-03-13T14:43:01.992971Z","iopub.status.idle":"2025-03-13T14:43:02.008235Z","shell.execute_reply.started":"2025-03-13T14:43:01.992943Z","shell.execute_reply":"2025-03-13T14:43:02.007325Z"},"trusted":true},"outputs":[{"name":"stdout","text":"GLEU Score: 0.6389\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import random\nimport torch\nfrom nltk.translate.bleu_score import sentence_bleu\n\n# Ensure model is on the correct device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Step 1: Select 5 random samples from val_dataset\nrandom_samples = random.sample(list(val_dataset), 5)\n\n# Step 2: Generate predictions and store results\npredictions = []\nreferences = []\n\nfor sample in random_samples:\n    incorrect_sentence = sample['Sentence']\n    corrected_sentence = sample['Corrected Sentence']\n\n    # Tokenize the incorrect sentence\n    inputs = tokenizer(incorrect_sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=50)\n\n    # Move inputs to the correct device\n    inputs = {key: value.to(device) for key, value in inputs.items()}\n\n    # Generate prediction\n    with torch.no_grad():\n        outputs = model.generate(input_ids=inputs['input_ids'], max_length=50, num_beams=4, early_stopping=True)\n\n    # Decode predicted sentence\n    predicted_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n    # Store results\n    predictions.append(predicted_sentence)\n    references.append(corrected_sentence)\n\n    # Print each sample\n    print(\"\\n--- Sample ---\")\n    print(f\"Incorrect Sentence: {incorrect_sentence}\")\n    print(f\"Corrected Sentence: {corrected_sentence}\")\n    print(f\"Predicted Sentence: {predicted_sentence}\")\n\n# Step 3: BLEU Score Calculation\ndef calculate_bleu(predictions, references):\n    bleu_scores = []\n    for pred, ref in zip(predictions, references):\n        pred_tokens = tokenizer.tokenize(pred)  # Use model's tokenizer\n        ref_tokens = tokenizer.tokenize(ref)  # Use model's tokenizer\n        bleu_scores.append(sentence_bleu([ref_tokens], pred_tokens))  # List of references needed\n    return sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0\n\n# Compute BLEU score\naverage_bleu = calculate_bleu(predictions, references)\nprint(f\"\\n✅ Average BLEU Score (5 samples): {average_bleu:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T14:43:06.483073Z","iopub.execute_input":"2025-03-13T14:43:06.483398Z","iopub.status.idle":"2025-03-13T14:43:07.558370Z","shell.execute_reply.started":"2025-03-13T14:43:06.483363Z","shell.execute_reply":"2025-03-13T14:43:07.557531Z"}},"outputs":[{"name":"stdout","text":"\n--- Sample ---\nIncorrect Sentence: பார்வதி வீட்டில் சாப்பிடுகிறாள்.\nCorrected Sentence: பார்வதி வீட்டில் செல்வேன்.\nPredicted Sentence: பார்வதி வீட்டில் படிக்கிறான்.\n\n--- Sample ---\nIncorrect Sentence: அவள் வீட்டில் சாப்பிடுவாள்.\nCorrected Sentence: அவள் வீட்டில் செல்வேன்.\nPredicted Sentence: அவள் வீட்டில் படிக்கிறாள்.\n\n--- Sample ---\nIncorrect Sentence: நாம் புத்தகத்தை செல்வேன்.\nCorrected Sentence: நாம் புத்தகத்தை செல்வேன்.\nPredicted Sentence: நாம் புத்தகத்தை செல்வேன்.\n\n--- Sample ---\nIncorrect Sentence: அவர்கள் பாடத்தை சாப்பிடுகிறாள்.\nCorrected Sentence: அவர்கள் பாடத்தை படிக்கிறான்.\nPredicted Sentence: அவர்கள் பாடத்தை சாப்பிடுகிறான்.\n\n--- Sample ---\nIncorrect Sentence: நான் வீட்டில் சாப்பிடுகிறாள்.\nCorrected Sentence: நான் வீட்டில் படிக்கிறாள்.\nPredicted Sentence: நான் வீட்டில் படிக்கிறாள்.\n\n✅ Average BLEU Score (5 samples): 0.6892\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"!pip install sacrebleu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T14:46:45.824158Z","iopub.execute_input":"2025-03-13T14:46:45.824524Z","iopub.status.idle":"2025-03-13T14:46:49.593054Z","shell.execute_reply.started":"2025-03-13T14:46:45.824495Z","shell.execute_reply":"2025-03-13T14:46:49.592173Z"}},"outputs":[{"name":"stdout","text":"Collecting sacrebleu\n  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.11.6)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (5.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->sacrebleu) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-3.1.1 sacrebleu-2.5.1\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import torch\nimport nltk\nimport sacrebleu\nfrom nltk.translate.bleu_score import sentence_bleu\nfrom nltk.translate.gleu_score import sentence_gleu  # Import for GLEU\n\n# Ensure nltk package is ready\nnltk.download('punkt')\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Define Tamil samples with similar errors\ntamil_samples = [\n    # 5-word sentences (5 samples)\n    {\"incorrect\": \"வாக்காளர் வழங்கப்பட்டது அரசு அறிவிப்பு\", \"corrected\": \"வாக்காளர்களுக்கு வழங்கப்பட்டது அரசு அறிவிப்பு\"},\n    {\"incorrect\": \"அறிவியல் தொழில்நுட்பம் வளர்ச்சி முக்கியம்\", \"corrected\": \"அறிவியல் மற்றும் தொழில்நுட்ப வளர்ச்சி முக்கியம்\"},\n    {\"incorrect\": \"அன்பு பாராட்டு செய்தார் மக்கள் முன்னிலையில்\", \"corrected\": \"அன்புப் பாராட்டு செய்தார் மக்கள் முன்னிலையில்\"},\n    {\"incorrect\": \"அவசர நடவடிக்க எடுக்க வேண்டும்\", \"corrected\": \"அவசர நடவடிக்கை எடுக்க வேண்டும்\"},\n    {\"incorrect\": \"நடிகர் பேசினார் ரசிகர்கள் கூட்டத்தில்\", \"corrected\": \"நடிகர் பேசினார் ரசிகர்கள் கூட்டத்தில்\"},\n\n    # 4-word sentences (8 samples)\n    {\"incorrect\": \"மழை காரணம் வெள்ளம் ஏற்பட்டது\", \"corrected\": \"மழை காரணமாக வெள்ளம் ஏற்பட்டது\"},\n    {\"incorrect\": \"நாடு முன்னேற்ற வளர்ச்சி இன்றியமையாது\", \"corrected\": \"நாடு முன்னேற்றம் வளர்ச்சி இன்றியமையாது\"},\n    {\"incorrect\": \"சுற்றுச்சூழல் பாதுகாப்பு மிக முக்கியம்\", \"corrected\": \"சுற்றுச்சூழல் பாதுகாப்பு மிக முக்கியம்\"},\n    {\"incorrect\": \"அவன் விரைவில் சென்று விட்டான்\", \"corrected\": \"அவன் விரைவாக சென்று விட்டான்\"},\n    {\"incorrect\": \"படிப்பு முடித்த வேலை பெற்றான்\", \"corrected\": \"படிப்பு முடித்து வேலை பெற்றான்\"},\n    {\"incorrect\": \"நேரம் செலவழிக்க மிக முக்கியம்\", \"corrected\": \"நேரம் செலவழிக்க மிக முக்கியம்\"},\n    {\"incorrect\": \"மகிழ்ச்சி உணர்வு மனதை உற்சாகம்\", \"corrected\": \"மகிழ்ச்சி உணர்வு மனதை உற்சாகம்\"},\n    {\"incorrect\": \"மழை காலநிலை கடுமையாக உள்ளது\", \"corrected\": \"மழைக்கால நிலை கடுமையாக உள்ளது\"},\n\n    # 3-word sentences (2 samples)\n    {\"incorrect\": \"நான் பெற்ற மதிப்பெண்\", \"corrected\": \"நான் பெற்ற மதிப்பெண்கள்\"},\n    {\"incorrect\": \"சிறந்த இசை பாடல்\", \"corrected\": \"சிறந்த இசைப் பாடல்\"},\n]\n\n\ntotal_bleu_score = 0.0\ntotal_gleu_score = 0.0\nreferences = []  # Store references for TER\nhypotheses = []  # Store hypotheses for TER\n\nnum_samples = len(tamil_samples)\n\nfor sample in tamil_samples:\n    incorrect_sentence = sample[\"incorrect\"]\n    corrected_sentence = sample[\"corrected\"]\n\n    # Tokenize the incorrect sentence\n    inputs = tokenizer(incorrect_sentence, return_tensors=\"pt\")\n\n    # Move inputs to the same device as the model (GPU if available)\n    inputs = {key: value.to(device) for key, value in inputs.items()}\n\n    # Generate the predicted sentence\n    with torch.no_grad():\n        outputs = model.generate(\n            input_ids=inputs[\"input_ids\"],\n            max_length=50,\n            num_beams=5,  \n            temperature=0.7,  \n            top_k=50, \n            top_p=0.9,\n            early_stopping=True\n        )\n\n    # Decode the predicted sentence\n    predicted_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n    # Compute BLEU score\n    reference = [nltk.word_tokenize(corrected_sentence)]\n    candidate = nltk.word_tokenize(predicted_sentence)\n    bleu_score = sentence_bleu(reference, candidate, weights=(0.5, 0.5))  # Bi-gram BLEU score\n    total_bleu_score += bleu_score\n\n    # Compute GLEU score\n    gleu_score = sentence_gleu(reference, candidate)\n    total_gleu_score += gleu_score\n\n    # Store sentences for TER calculation\n    references.append([corrected_sentence])\n    hypotheses.append(predicted_sentence)\n\n    # Print results\n    print(\"\\nIncorrect Sentence:\", incorrect_sentence)\n    print(\"Corrected Sentence:\", corrected_sentence)\n    print(\"Predicted Sentence:\", predicted_sentence)\n    print(\"BLEU Score: {:.2f}\".format(bleu_score))\n    print(\"GLEU Score: {:.2f}\".format(gleu_score))\n\n# Compute the average BLEU and GLEU scores\naverage_bleu_score = total_bleu_score / num_samples\naverage_gleu_score = total_gleu_score / num_samples\n\n# Compute TER score\nter_score = sacrebleu.corpus_ter(hypotheses, references).score\n\nprint(\"\\nAverage BLEU Score: {:.2f}\".format(average_bleu_score))\nprint(\"Average GLEU Score: {:.2f}\".format(average_gleu_score))\nprint(\"TER Score: {:.2f}\".format(ter_score))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T14:46:53.315329Z","iopub.execute_input":"2025-03-13T14:46:53.315668Z","iopub.status.idle":"2025-03-13T14:46:57.499276Z","shell.execute_reply.started":"2025-03-13T14:46:53.315642Z","shell.execute_reply":"2025-03-13T14:46:57.498594Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nIncorrect Sentence: வாக்காளர் வழங்கப்பட்டது அரசு அறிவிப்பு\nCorrected Sentence: வாக்காளர்களுக்கு வழங்கப்பட்டது அரசு அறிவிப்பு\nPredicted Sentence: வாக்காளர் வழங்கப்பட்டது அரசு அறிவிப்பு.\nBLEU Score: 0.55\nGLEU Score: 0.43\n\nIncorrect Sentence: அறிவியல் தொழில்நுட்பம் வளர்ச்சி முக்கியம்\nCorrected Sentence: அறிவியல் மற்றும் தொழில்நுட்ப வளர்ச்சி முக்கியம்\nPredicted Sentence: அறிவியல் தொழில்நுட்பம் வளர்ச்சி முக்கியம்\nBLEU Score: 0.39\nGLEU Score: 0.29\n\nIncorrect Sentence: அன்பு பாராட்டு செய்தார் மக்கள் முன்னிலையில்\nCorrected Sentence: அன்புப் பாராட்டு செய்தார் மக்கள் முன்னிலையில்\nPredicted Sentence: அன்பு பாராட்டு செய்தார் மக்கள் முன்னிலையில்.\nBLEU Score: 0.63\nGLEU Score: 0.56\n\nIncorrect Sentence: அவசர நடவடிக்க எடுக்க வேண்டும்\nCorrected Sentence: அவசர நடவடிக்கை எடுக்க வேண்டும்\nPredicted Sentence: அவசர நடவடிக்க எடுக்க வேண்டும்.\nBLEU Score: 0.39\nGLEU Score: 0.29\n\nIncorrect Sentence: நடிகர் பேசினார் ரசிகர்கள் கூட்டத்தில்\nCorrected Sentence: நடிகர் பேசினார் ரசிகர்கள் கூட்டத்தில்\nPredicted Sentence: நடிகர் பேசினார் ரசிகர்கள் கூட்டத்தில் விளையாடுகிறோம்.\nBLEU Score: 0.63\nGLEU Score: 0.56\n\nIncorrect Sentence: மழை காரணம் வெள்ளம் ஏற்பட்டது\nCorrected Sentence: மழை காரணமாக வெள்ளம் ஏற்பட்டது\nPredicted Sentence: மழை காரணம் வெள்ளம் ஏற்பட்டது.\nBLEU Score: 0.39\nGLEU Score: 0.29\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 2-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n","output_type":"stream"},{"name":"stdout","text":"\nIncorrect Sentence: நாடு முன்னேற்ற வளர்ச்சி இன்றியமையாது\nCorrected Sentence: நாடு முன்னேற்றம் வளர்ச்சி இன்றியமையாது\nPredicted Sentence: நாடு முன்னேற்றத்தை இன்றியமையாதான் சாப்பிடுகிறான்.\nBLEU Score: 0.45\nGLEU Score: 0.07\n\nIncorrect Sentence: சுற்றுச்சூழல் பாதுகாப்பு மிக முக்கியம்\nCorrected Sentence: சுற்றுச்சூழல் பாதுகாப்பு மிக முக்கியம்\nPredicted Sentence: சுற்றுச்சூழல் பாதுகாப்பு மிக முக்கியம்.\nBLEU Score: 0.77\nGLEU Score: 0.71\n\nIncorrect Sentence: அவன் விரைவில் சென்று விட்டான்\nCorrected Sentence: அவன் விரைவாக சென்று விட்டான்\nPredicted Sentence: அவன் விரைவில் சென்று விட்டான்.\nBLEU Score: 0.39\nGLEU Score: 0.29\n\nIncorrect Sentence: படிப்பு முடித்த வேலை பெற்றான்\nCorrected Sentence: படிப்பு முடித்து வேலை பெற்றான்\nPredicted Sentence: படி படித்த முடித்த வேலை பெற்றான்.\nBLEU Score: 0.26\nGLEU Score: 0.17\n\nIncorrect Sentence: நேரம் செலவழிக்க மிக முக்கியம்\nCorrected Sentence: நேரம் செலவழிக்க மிக முக்கியம்\nPredicted Sentence: நேரம் செலவழிக்க மிக முக்கியம்.\nBLEU Score: 0.77\nGLEU Score: 0.71\n\nIncorrect Sentence: மகிழ்ச்சி உணர்வு மனதை உற்சாகம்\nCorrected Sentence: மகிழ்ச்சி உணர்வு மனதை உற்சாகம்\nPredicted Sentence: மகிழ்ச்சி உணர்வு மனதை உற்சாகம் படிக்கிறாள்.\nBLEU Score: 0.63\nGLEU Score: 0.56\n\nIncorrect Sentence: மழை காலநிலை கடுமையாக உள்ளது\nCorrected Sentence: மழைக்கால நிலை கடுமையாக உள்ளது\nPredicted Sentence: மழை காலநிலை கடுமையாக உள்ளது.\nBLEU Score: 0.32\nGLEU Score: 0.21\n\nIncorrect Sentence: நான் பெற்ற மதிப்பெண்\nCorrected Sentence: நான் பெற்ற மதிப்பெண்கள்\nPredicted Sentence: நான் பெற்ற மதிப்பெண்\nBLEU Score: 0.58\nGLEU Score: 0.50\n\nIncorrect Sentence: சிறந்த இசை பாடல்\nCorrected Sentence: சிறந்த இசைப் பாடல்\nPredicted Sentence: சிறந்த இசை பாடல்\nBLEU Score: 0.82\nGLEU Score: 0.33\n\nAverage BLEU Score: 0.53\nAverage GLEU Score: 0.40\nTER Score: 50.00\n","output_type":"stream"}],"execution_count":13}]}