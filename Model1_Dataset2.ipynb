{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11022994,"sourceType":"datasetVersion","datasetId":6864256}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\n# Load your dataset\nfile_path = \"/kaggle/input/final1/tamil_grammar_large_dataset.csv\"  # Update with your actual file path\ndf = pd.read_csv(file_path)\n\n# Check the first few rows to understand the structure\nprint(df.head())\n\n# Remove rows with any null values in the dataset\ndf_cleaned = df.dropna()\n\n# Remove duplicate rows\ndf_cleaned = df_cleaned.drop_duplicates()\n\n# Optionally, you can reset the index after cleaning\ndf_cleaned = df_cleaned.reset_index(drop=True)\n\n# Check the cleaned dataset\nprint(df_cleaned.head())\n\n# Save the cleaned dataset to a new CSV file\ndf_cleaned.to_csv(\"cleaned_dataset.csv\", index=False)\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-03-13T19:03:39.663521Z","iopub.execute_input":"2025-03-13T19:03:39.663838Z","iopub.status.idle":"2025-03-13T19:03:40.050787Z","shell.execute_reply.started":"2025-03-13T19:03:39.663815Z","shell.execute_reply":"2025-03-13T19:03:40.049761Z"},"trusted":true},"outputs":[{"name":"stdout","text":"                          Sentence              Error Type  \\\n0  அவர்கள் பள்ளிக்கு சாப்பிடுவாள்.          Spelling Error   \n1     நாம் பாடத்தை படிக்கிறார்கள்.  Subject-Verb Agreement   \n2     அவன் பள்ளிக்கு சாப்பிடுவாள்.          Spelling Error   \n3    அவர்கள் பந்து விளையாடுகிறோம்.                No Error   \n4  நான் புத்தகத்தை விளையாடுகிறான்.  Subject-Verb Agreement   \n\n               Corrected Sentence  \n0  அவர்கள் பள்ளிக்கு படிக்கிறாள்.  \n1          நாம் பாடத்தை செல்வேன்.  \n2  அவன் பள்ளிக்கு விளையாடுகிறோம்.  \n3   அவர்கள் பந்து விளையாடுகிறோம்.  \n4    நான் புத்தகத்தை படிக்கிறான்.  \n                          Sentence              Error Type  \\\n0  அவர்கள் பள்ளிக்கு சாப்பிடுவாள்.          Spelling Error   \n1     நாம் பாடத்தை படிக்கிறார்கள்.  Subject-Verb Agreement   \n2     அவன் பள்ளிக்கு சாப்பிடுவாள்.          Spelling Error   \n3    அவர்கள் பந்து விளையாடுகிறோம்.                No Error   \n4  நான் புத்தகத்தை விளையாடுகிறான்.  Subject-Verb Agreement   \n\n               Corrected Sentence  \n0  அவர்கள் பள்ளிக்கு படிக்கிறாள்.  \n1          நாம் பாடத்தை செல்வேன்.  \n2  அவன் பள்ளிக்கு விளையாடுகிறோம்.  \n3   அவர்கள் பந்து விளையாடுகிறோம்.  \n4    நான் புத்தகத்தை படிக்கிறான்.  \n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_MODE\"] = \"disabled\"\n","metadata":{"execution":{"iopub.status.busy":"2025-03-13T19:03:43.645000Z","iopub.execute_input":"2025-03-13T19:03:43.645367Z","iopub.status.idle":"2025-03-13T19:03:43.649199Z","shell.execute_reply.started":"2025-03-13T19:03:43.645316Z","shell.execute_reply":"2025-03-13T19:03:43.648227Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import BartTokenizer, EncoderDecoderModel, Trainer, TrainingArguments\nfrom sklearn.model_selection import train_test_split\nfrom datasets import Dataset\n\n\n# Load the cleaned dataset\ndf_cleaned = pd.read_csv(\"cleaned_dataset.csv\")\n\n# Split the dataset into training and validation sets\ntrain_df, val_df = train_test_split(df_cleaned, test_size=0.1)\n\n# Convert the dataframe to Hugging Face dataset format\ntrain_dataset = Dataset.from_pandas(train_df)\nval_dataset = Dataset.from_pandas(val_df)\nfrom transformers import MBart50Tokenizer, MBartForConditionalGeneration\n\n# Load model and tokenizer\nmodel_name = \"facebook/mbart-large-50-many-to-one-mmt\"  # Example multilingual model\ntokenizer = MBart50Tokenizer.from_pretrained(model_name)\nmodel = MBartForConditionalGeneration.from_pretrained(model_name)\n\n# Set the decoder_start_token_id\nmodel.config.decoder_start_token_id = tokenizer.pad_token_id  # You can also use tokenizer.bos_token_id if available\nmodel.config.pad_token_id = tokenizer.pad_token_id \n# Set the output_hidden_states flag to True\n\n\n\n# Tokenizer function\ndef preprocess_function(examples):\n    inputs = examples['Sentence']\n    targets = examples['Corrected Sentence']\n    \n    # Tokenize the sentences (input and target)\n    model_inputs = tokenizer(inputs, max_length=10, truncation=True, padding=\"max_length\")\n    labels = tokenizer(targets, max_length=10, truncation=True, padding=\"max_length\")\n    \n    # Add the labels to the model inputs\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    \n    return model_inputs\n\n# Apply tokenization on train and validation datasets\ntrain_dataset = train_dataset.map(preprocess_function, batched=True)\nval_dataset = val_dataset.map(preprocess_function, batched=True)\n\n# Set up training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",          # Output directory\n    eval_strategy=\"epoch\",           # Evaluation after each epoch\n    learning_rate=5e-5,              # Learning rate\n    per_device_train_batch_size=16,   # Batch size for training\n    per_device_eval_batch_size=16,    # Batch size for evaluation\n    num_train_epochs=10,              # Number of training epochs\n    weight_decay=0.01,               # Weight decay to avoid overfitting\n    save_total_limit=2,              # Limit on the number of saved checkpoints\n    logging_dir=\"./logs\",\n    warmup_steps=int(0.1 * len(train_dataset)),\n    lr_scheduler_type=\"linear\",\n    gradient_accumulation_steps=2,\n    max_grad_norm=1.0,\n    run_name=\"tamil-error-correction\",\n    report_to=[]\n    # Specify a unique run name\n)\n\n# Create Trainer with WandB tracking\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=tokenizer,  # Make sure the tokenizer is passed for padding, truncation\n    data_collator=None,\n)\n\n# Train the model\ntrainer.train()\n\n# Save the trained model\ntrainer.save_model(\"trained_model\")\n\n# Optionally, evaluate the model on validation set\nresults = trainer.evaluate(val_dataset)\nprint(results)\n","metadata":{"execution":{"iopub.status.busy":"2025-03-13T19:03:52.727053Z","iopub.execute_input":"2025-03-13T19:03:52.727326Z","iopub.status.idle":"2025-03-13T19:13:45.129067Z","shell.execute_reply.started":"2025-03-13T19:03:52.727307Z","shell.execute_reply":"2025-03-13T19:13:45.128119Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/461 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"deb87fc6471f48edaf4c5f7cbb9b1230"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9586d4f6eeae4688a30d69a77d6627a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"748d7446654f4e7fb44047cdefe70e95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.51k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c17b945662104c8483034e5c28dd70ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"526653eb54f84c4ab8ab158966111b74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/268 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc5a0088ad7b4eaa8af7a1575d7dbad9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1775 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25580013eda84f61a387301a2b0d3c39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/198 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22e483dea0aa4a5c84738f755574abd5"}},"metadata":{}},{"name":"stderr","text":"<ipython-input-3-023ee54606b6>:69: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='280' max='280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [280/280 08:42, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>2.904040</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.264648</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.801584</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.248768</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.178257</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>0.161620</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>No log</td>\n      <td>0.156355</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>No log</td>\n      <td>0.147738</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>No log</td>\n      <td>0.146722</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>No log</td>\n      <td>0.146692</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'num_beams': 5, 'forced_bos_token_id': 250004}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [7/7 00:01]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.14669166505336761, 'eval_runtime': 2.2448, 'eval_samples_per_second': 88.203, 'eval_steps_per_second': 3.118, 'epoch': 10.0}\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Extract logs from Trainer state\nlog_history = trainer.state.log_history\n\n# Separate training and validation losses\ntrain_losses = [entry['loss'] for entry in log_history if 'loss' in entry]\neval_losses = [entry['eval_loss'] for entry in log_history if 'eval_loss' in entry]\nlearning_rates = [entry['learning_rate'] for entry in log_history if 'learning_rate' in entry]\n\n# Create x-axis for epochs\n\nepochs_eval = range(1, len(eval_losses) + 1)\n\n# Plot validation loss\nplt.figure(figsize=(6, 4))\nplt.plot(epochs_eval, eval_losses, label=\"Validation Loss\", marker='o', color='red')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Validation Loss over Epochs\")\nplt.legend()\nplt.grid()\nplt.show()\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T19:23:47.484738Z","iopub.execute_input":"2025-03-13T19:23:47.485055Z","iopub.status.idle":"2025-03-13T19:23:47.661938Z","shell.execute_reply.started":"2025-03-13T19:23:47.485030Z","shell.execute_reply":"2025-03-13T19:23:47.661101Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 600x400 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import torch\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom nltk.translate.bleu_score import sentence_bleu\n\n\n# Check if GPU is available and move the model to GPU if it is\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = model.to(device)\n\n# Generate predictions on the validation set\npredictions = []\nreferences = []\n\n# Use the model to generate predictions on the validation set\nfor example in val_dataset:\n    input_ids = tokenizer(example['Sentence'], return_tensors='pt', padding=True, truncation=True, max_length=35).input_ids\n    \n    # Move input_ids to the correct device (same as the model)\n    input_ids = input_ids.to(device)\n    \n    output_ids = model.generate(input_ids)\n    decoded_prediction = tokenizer.decode(output_ids[0], skip_special_tokens=True)  # Use tokenizer's decode method\n\n    predictions.append(decoded_prediction)\n    references.append(example['Corrected Sentence'])\n\n# BLEU Score Calculation (with n-gram overlap)\ndef calculate_bleu(predictions, references):\n    bleu_scores = []\n    for pred, ref in zip(predictions, references):\n        # Tokenize sentences and calculate BLEU score\n        pred_tokens = pred.split()\n        ref_tokens = ref.split()\n        bleu_scores.append(sentence_bleu([ref_tokens], pred_tokens))  # List of references is passed to sentence_bleu\n    return sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0\n\n\n# Calculate BLEU\nbleu_score = calculate_bleu(predictions, references)\n\n\n# Print the results\nprint(f\"BLEU Score: {bleu_score:.4f}\")\n\n","metadata":{"execution":{"iopub.status.busy":"2025-03-13T19:23:56.810786Z","iopub.execute_input":"2025-03-13T19:23:56.811191Z","iopub.status.idle":"2025-03-13T19:24:38.727276Z","shell.execute_reply.started":"2025-03-13T19:23:56.811156Z","shell.execute_reply":"2025-03-13T19:24:38.726237Z"},"trusted":true},"outputs":[{"name":"stdout","text":"BLEU Score: 0.8181\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 4-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 3-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!pip install bert_score\nfrom bert_score import score\nP, R, F1 = score(predictions, references, lang=\"ta\")  # Adjust the language if necessary (e.g., \"ta\" for Tamil)\n\n# Print BERT scores\nprint(f\"BERT Precision: {P.mean():.4f}\")\nprint(f\"BERT Recall: {R.mean():.4f}\")\nprint(f\"BERT F1 Score: {F1.mean():.4f}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-13T19:25:06.549624Z","iopub.execute_input":"2025-03-13T19:25:06.549926Z","iopub.status.idle":"2025-03-13T19:25:21.867123Z","shell.execute_reply.started":"2025-03-13T19:25:06.549902Z","shell.execute_reply":"2025-03-13T19:25:21.866055Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting bert_score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.5.1+cu121)\nRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.2.3)\nRequirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.47.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert_score) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.32.3)\nRequirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.67.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert_score) (3.7.5)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert_score) (24.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2025.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.29.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.4.5)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.4.7)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (3.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2025.1.31)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->bert_score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->bert_score) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->bert_score) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->bert_score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->bert_score) (2024.2.0)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: bert_score\nSuccessfully installed bert_score-0.3.13\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33fcb0c29fdb475ea7bbe88b05456af7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d17fb7cd49964fa5a15830c72d4c72a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e4f9958e0f048b09c0ade77c6dad54b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2e257b9d38a4aa2baba62d27bd82bfe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d26616a8d5ae457aa5539284dc139b63"}},"metadata":{}},{"name":"stdout","text":"BERT Precision: 0.8766\nBERT Recall: 0.8947\nBERT F1 Score: 0.8851\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import nltk\n\ndef calculate_ter(references, predictions):\n    \"\"\"\n    Compute TER (Translation Edit Rate) score.\n    references: list of reference sentences (the correct sentences)\n    predictions: list of generated sentences (the sentences predicted by the model)\n    \"\"\"\n    # Initialize the TER scores\n    ter_scores = []\n    \n    # Loop over all the sentences\n    for ref, hyp in zip(references, predictions):\n        ref_tokens = ref.split()  # Tokenize the reference sentence\n        hyp_tokens = hyp.split()  # Tokenize the hypothesis sentence\n\n        # Find the minimum edit distance (substitutions, insertions, deletions)\n        edits = nltk.edit_distance(ref_tokens, hyp_tokens)\n\n        # TER is calculated as (number of edits + len(reference) - len(hypothesis)) / len(reference)\n        ter = (edits + len(ref_tokens) - len(hyp_tokens)) / len(ref_tokens)\n        ter_scores.append(ter)\n\n    # Average TER score across all sentences\n    avg_ter = sum(ter_scores) / len(ter_scores) if ter_scores else 0\n    return avg_ter\n\n\n\nter_score = calculate_ter(references, predictions)\nprint(f\"TER Score: {ter_score:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-03-13T19:25:29.051625Z","iopub.execute_input":"2025-03-13T19:25:29.051972Z","iopub.status.idle":"2025-03-13T19:25:29.060683Z","shell.execute_reply.started":"2025-03-13T19:25:29.051939Z","shell.execute_reply":"2025-03-13T19:25:29.059768Z"},"trusted":true},"outputs":[{"name":"stdout","text":"TER Score: 0.2525\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import nltk\nfrom collections import Counter\n\ndef calculate_gleu(references, predictions, max_order=4):\n    \"\"\"\n    Compute GLEU score.\n    references: list of reference sentences (the correct sentences)\n    predictions: list of generated sentences (the sentences predicted by the model)\n    max_order: maximum n-gram length for the BLEU calculation (default is 4)\n    \"\"\"\n    def get_ngrams(tokens, n):\n        return [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n\n    def compute_sentence_gleu(ref_tokens, hyp_tokens):\n        \"\"\"\n        Compute the GLEU score for a single sentence pair.\n        \"\"\"\n        total_ref_ngrams = Counter()\n        total_hyp_ngrams = Counter()\n        total_match_ngrams = Counter()\n\n        for n in range(1, max_order + 1):\n            ref_ngrams = get_ngrams(ref_tokens, n)\n            hyp_ngrams = get_ngrams(hyp_tokens, n)\n            \n            ref_ngrams_count = Counter(ref_ngrams)\n            hyp_ngrams_count = Counter(hyp_ngrams)\n\n            total_ref_ngrams.update(ref_ngrams_count)\n            total_hyp_ngrams.update(hyp_ngrams_count)\n            total_match_ngrams.update(ref_ngrams_count & hyp_ngrams_count)  # Intersection for matching n-grams\n\n        # Compute precision and recall\n        precision = sum(total_match_ngrams.values()) / sum(total_hyp_ngrams.values()) if total_hyp_ngrams else 0\n        recall = sum(total_match_ngrams.values()) / sum(total_ref_ngrams.values()) if total_ref_ngrams else 0\n\n        # Compute GLEU score (harmonic mean of precision and recall)\n        if precision + recall > 0:\n            gleu = (1 + 0.5) * (precision * recall) / (0.5 * precision + recall)\n        else:\n            gleu = 0\n        return gleu\n\n    # Initialize the GLEU scores\n    gleu_scores = []\n\n    # Loop over all reference-prediction pairs\n    for ref, hyp in zip(references, predictions):\n        ref_tokens = ref.split()  # Tokenize the reference sentence\n        hyp_tokens = hyp.split()  # Tokenize the hypothesis sentence\n\n        gleu_score = compute_sentence_gleu(ref_tokens, hyp_tokens)\n        gleu_scores.append(gleu_score)\n\n    # Average GLEU score across all sentences\n    avg_gleu = sum(gleu_scores) / len(gleu_scores) if gleu_scores else 0\n    return avg_gleu\n\ngleu_score = calculate_gleu(references, predictions)\nprint(f\"GLEU Score: {gleu_score:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-03-13T19:25:33.952785Z","iopub.execute_input":"2025-03-13T19:25:33.953108Z","iopub.status.idle":"2025-03-13T19:25:33.968723Z","shell.execute_reply.started":"2025-03-13T19:25:33.953081Z","shell.execute_reply":"2025-03-13T19:25:33.967615Z"},"trusted":true},"outputs":[{"name":"stdout","text":"GLEU Score: 0.6212\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import random\nimport torch\nfrom nltk.translate.bleu_score import sentence_bleu\n\n# Ensure model is on the correct device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Step 1: Select 5 random samples from val_dataset\nrandom_samples = random.sample(list(val_dataset), 5)\n\n# Step 2: Generate predictions and store results\npredictions = []\nreferences = []\n\nfor sample in random_samples:\n    incorrect_sentence = sample['Sentence']\n    corrected_sentence = sample['Corrected Sentence']\n\n    # Tokenize the incorrect sentence\n    inputs = tokenizer(incorrect_sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=50)\n\n    # Move inputs to the correct device\n    inputs = {key: value.to(device) for key, value in inputs.items()}\n\n    # Generate prediction\n    with torch.no_grad():\n        outputs = model.generate(input_ids=inputs['input_ids'], max_length=50, num_beams=4, early_stopping=True)\n\n    # Decode predicted sentence\n    predicted_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n    # Store results\n    predictions.append(predicted_sentence)\n    references.append(corrected_sentence)\n\n    # Print each sample\n    print(\"\\n--- Sample ---\")\n    print(f\"Incorrect Sentence: {incorrect_sentence}\")\n    print(f\"Corrected Sentence: {corrected_sentence}\")\n    print(f\"Predicted Sentence: {predicted_sentence}\")\n\n# Step 3: BLEU Score Calculation\ndef calculate_bleu(predictions, references):\n    bleu_scores = []\n    for pred, ref in zip(predictions, references):\n        pred_tokens = tokenizer.tokenize(pred)  # Use model's tokenizer\n        ref_tokens = tokenizer.tokenize(ref)  # Use model's tokenizer\n        bleu_scores.append(sentence_bleu([ref_tokens], pred_tokens))  # List of references needed\n    return sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0\n\n# Compute BLEU score\naverage_bleu = calculate_bleu(predictions, references)\nprint(f\"\\n✅ Average BLEU Score (5 samples): {average_bleu:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T19:25:46.789795Z","iopub.execute_input":"2025-03-13T19:25:46.790089Z","iopub.status.idle":"2025-03-13T19:25:47.642438Z","shell.execute_reply.started":"2025-03-13T19:25:46.790067Z","shell.execute_reply":"2025-03-13T19:25:47.641661Z"}},"outputs":[{"name":"stdout","text":"\n--- Sample ---\nIncorrect Sentence: அவள் பாடத்தை விளையாடுகிறான்.\nCorrected Sentence: அவள் பாடத்தை படிக்கிறாள்.\nPredicted Sentence: அவள் பாடத்தை சாப்பிடுகிறான்.\n\n--- Sample ---\nIncorrect Sentence: அவன் பாடத்தை படிக்கிறான்.\nCorrected Sentence: அவன் பாடத்தை படிக்கிறான்.\nPredicted Sentence: அவன் பாடத்தை படிக்கிறான்.\n\n--- Sample ---\nIncorrect Sentence: நாம் பந்து விளையாடுகிறான்.\nCorrected Sentence: நாம் பந்து படிக்கிறாள்.\nPredicted Sentence: நாம் பந்து சாப்பிடுகிறான்.\n\n--- Sample ---\nIncorrect Sentence: அவர்கள் பந்து செல்கிறான்.\nCorrected Sentence: அவர்கள் பந்து படிக்கிறான்.\nPredicted Sentence: அவர்கள் பந்து செல்வேன்.\n\n--- Sample ---\nIncorrect Sentence: அவள் பாடத்தை விளையாடுகிறோம்.\nCorrected Sentence: அவள் பாடத்தை விளையாடுகிறோம்.\nPredicted Sentence: அவள் பாடத்தை விளையாடுகிறோம்.\n\n✅ Average BLEU Score (5 samples): 0.6627\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"!pip install sacrebleu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T19:25:56.806294Z","iopub.execute_input":"2025-03-13T19:25:56.806650Z","iopub.status.idle":"2025-03-13T19:26:00.649608Z","shell.execute_reply.started":"2025-03-13T19:25:56.806619Z","shell.execute_reply":"2025-03-13T19:26:00.648754Z"}},"outputs":[{"name":"stdout","text":"Collecting sacrebleu\n  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.11.6)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (5.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->sacrebleu) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-3.1.1 sacrebleu-2.5.1\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import torch\nimport nltk\nimport sacrebleu\nfrom nltk.translate.bleu_score import sentence_bleu\n\n# Ensure nltk package is ready\nnltk.download('punkt')\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Define Tamil samples with similar errors\ntamil_samples = [\n    # 5-word sentences (5 samples)\n    {\"incorrect\": \"அன்பு பாராட்டு செய்தார் மக்கள் முன்னிலையில்\", \"corrected\": \"அன்புப் பாராட்டு செய்தார் மக்கள் முன்னிலையில்\"},\n    {\"incorrect\": \"நடிகர் பேசினார் ரசிகர்கள் கூட்டத்தில்\", \"corrected\": \"நடிகர் பேசினார் ரசிகர்கள் கூட்டத்தில்\"},\n\n    # 4-word sentences (8 samples)\n    {\"incorrect\": \"மழை காரணம் வெள்ளம் ஏற்பட்டது\", \"corrected\": \"மழை காரணமாக வெள்ளம் ஏற்பட்டது\"},\n    {\"incorrect\": \"நாடு முன்னேற்ற வளர்ச்சி இன்றியமையாது\", \"corrected\": \"நாடு முன்னேற்றம் வளர்ச்சி இன்றியமையாது\"},\n    {\"incorrect\": \"அவன் விரைவில் சென்று விட்டான்\", \"corrected\": \"அவன் விரைவாக சென்று விட்டான்\"},\n    {\"incorrect\": \"படிப்பு முடித்த வேலை பெற்றான்\", \"corrected\": \"படிப்பு முடித்து வேலை பெற்றான்\"},\n    {\"incorrect\": \"மகிழ்ச்சி உணர்வு மனதை உற்சாகம்\", \"corrected\": \"மகிழ்ச்சி உணர்வு மனதை உற்சாகம்\"},\n\n    # 3-word sentences (2 samples)\n    {\"incorrect\": \"நான் பெற்ற மதிப்பெண்\", \"corrected\": \"நான் பெற்ற மதிப்பெண்கள்\"},\n]\n\ntotal_bleu_score = 0.0  # Store cumulative BLEU score\ntotal_ter_score = 0.0   # Store cumulative TER score\nnum_samples = len(tamil_samples)\n\nfor sample in tamil_samples:\n    incorrect_sentence = sample[\"incorrect\"]\n    corrected_sentence = sample[\"corrected\"]\n\n    # Tokenize the incorrect sentence\n    inputs = tokenizer(incorrect_sentence, return_tensors=\"pt\")\n\n    # Move inputs to the same device as the model (GPU if available)\n    inputs = {key: value.to(device) for key, value in inputs.items()}\n\n    # Generate the predicted sentence\n    with torch.no_grad():\n        outputs = model.generate(\n            input_ids=inputs[\"input_ids\"],\n            max_length=50,\n            num_beams=5,  \n            temperature=0.7,  \n            top_k=50, \n            top_p=0.9,\n            early_stopping=True\n        )\n\n    # Decode the predicted sentence\n    predicted_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n    # Compute BLEU score\n    reference = [nltk.word_tokenize(corrected_sentence)]\n    candidate = nltk.word_tokenize(predicted_sentence)\n    bleu_score = sentence_bleu(reference, candidate, weights=(0.5, 0.5))  # Bi-gram BLEU score\n    total_bleu_score += bleu_score\n\n    # Compute TER score using sacrebleu\n    # Compute TER score using sacrebleu\n    ter_score = sacrebleu.sentence_ter(predicted_sentence, [corrected_sentence]).score\n    total_ter_score += ter_score  # Extract the score before adding\n\n\n    # Print results\n    print(\"\\nIncorrect Sentence:\", incorrect_sentence)\n    print(\"Corrected Sentence:\", corrected_sentence)\n    print(\"Predicted Sentence:\", predicted_sentence)\n    print(\"BLEU Score: {:.2f}\".format(bleu_score))\n    print(\"TER Score: {:.2f}\".format(ter_score))\n\n# Compute the average BLEU and TER scores\naverage_bleu_score = total_bleu_score / num_samples\naverage_ter_score = total_ter_score / num_samples\n\nprint(\"\\nAverage BLEU Score: {:.2f}\".format(average_bleu_score))\nprint(\"Average TER Score: {:.2f}\".format(average_ter_score))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T19:36:24.986653Z","iopub.execute_input":"2025-03-13T19:36:24.986977Z","iopub.status.idle":"2025-03-13T19:36:27.486056Z","shell.execute_reply.started":"2025-03-13T19:36:24.986947Z","shell.execute_reply":"2025-03-13T19:36:27.485199Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n\nIncorrect Sentence: அன்பு பாராட்டு செய்தார் மக்கள் முன்னிலையில்\nCorrected Sentence: அன்புப் பாராட்டு செய்தார் மக்கள் முன்னிலையில்\nPredicted Sentence: அன்பு படிக்கிறாள் மக்கள் முன்னிலை விளையாடுகிறோம்.\nBLEU Score: 0.41\nTER Score: 100.00\n\nIncorrect Sentence: நடிகர் பேசினார் ரசிகர்கள் கூட்டத்தில்\nCorrected Sentence: நடிகர் பேசினார் ரசிகர்கள் கூட்டத்தில்\nPredicted Sentence: Actor பேசினார் சாப்பிடுகிறான்கிறான்\nBLEU Score: 0.41\nTER Score: 75.00\n\nIncorrect Sentence: மழை காரணம் வெள்ளம் ஏற்பட்டது\nCorrected Sentence: மழை காரணமாக வெள்ளம் ஏற்பட்டது\nPredicted Sentence: மழை படிக்கிறாள் செல்வேன்.\nBLEU Score: 0.50\nTER Score: 75.00\n\nIncorrect Sentence: நாடு முன்னேற்ற வளர்ச்சி இன்றியமையாது\nCorrected Sentence: நாடு முன்னேற்றம் வளர்ச்சி இன்றியமையாது\nPredicted Sentence: நாடு சாப்பிடுகிறான் சாப்பிடுகிறான்.\nBLEU Score: 0.50\nTER Score: 75.00\n\nIncorrect Sentence: அவன் விரைவில் சென்று விட்டான்\nCorrected Sentence: அவன் விரைவாக சென்று விட்டான்\nPredicted Sentence: அவன் சாப்பிடுகிறான்.\nBLEU Score: 0.41\nTER Score: 75.00\n\nIncorrect Sentence: படிப்பு முடித்த வேலை பெற்றான்\nCorrected Sentence: படிப்பு முடித்து வேலை பெற்றான்\nPredicted Sentence: படிப்பு விளையாடுகிறோம் விளையாடுகிறோம்.\nBLEU Score: 0.50\nTER Score: 75.00\n\nIncorrect Sentence: மகிழ்ச்சி உணர்வு மனதை உற்சாகம்\nCorrected Sentence: மகிழ்ச்சி உணர்வு மனதை உற்சாகம்\nPredicted Sentence: Happy Sentiment மனதை உற்சாகம்\nBLEU Score: 0.41\nTER Score: 50.00\n\nIncorrect Sentence: நான் பெற்ற மதிப்பெண்\nCorrected Sentence: நான் பெற்ற மதிப்பெண்கள்\nPredicted Sentence: நான் பெற்ற மதிப்பெண்\nBLEU Score: 0.58\nTER Score: 33.33\n\nAverage BLEU Score: 0.47\nAverage TER Score: 69.79\n","output_type":"stream"}],"execution_count":22}]}