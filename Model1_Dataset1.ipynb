{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11022659,"sourceType":"datasetVersion","datasetId":6863984}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\n# Load your dataset\nfile_path = \"/kaggle/input/5lettersamples/Error Annotated Corpus (1).csv\"  # Update with your actual file path\ndf = pd.read_csv(file_path)\n\n# Check the first few rows to understand the structure\nprint(df.head())\n\n# Remove rows with any null values in the dataset\ndf_cleaned = df.dropna()\n\n# Remove duplicate rows\ndf_cleaned = df_cleaned.drop_duplicates()\n\n# Optionally, you can reset the index after cleaning\ndf_cleaned = df_cleaned.reset_index(drop=True)\n\n# Check the cleaned dataset\nprint(df_cleaned.head())\n\n# Save the cleaned dataset to a new CSV file\ndf_cleaned.to_csv(\"cleaned_dataset.csv\", index=False)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:15:04.530801Z","iopub.execute_input":"2025-03-13T18:15:04.531159Z","iopub.status.idle":"2025-03-13T18:15:04.619664Z","shell.execute_reply.started":"2025-03-13T18:15:04.531130Z","shell.execute_reply":"2025-03-13T18:15:04.618830Z"}},"outputs":[{"name":"stdout","text":"  Error word & consecutive word     Corrected words & its    Annotation\n0               10கனநீர் உலைகள்           10கணநீர் உலைகள்  வேற்றெழுத்து\n1                   அகளவிரித்து               அகலவிரித்து  வேற்றெழுத்து\n2      அணைத்து ஊழியர்களுக்குமான  அனைத்து ஊழியர்களுக்குமான  வேற்றெழுத்து\n3               அதள பாதாளதுக்கு         அதல பாதாளத்துக்கு  வேற்றெழுத்து\n4           அதற்குறிய தீர்வுகளை       அதற்குரிய தீர்வுகளை  வேற்றெழுத்து\n  Error word & consecutive word     Corrected words & its    Annotation\n0               10கனநீர் உலைகள்           10கணநீர் உலைகள்  வேற்றெழுத்து\n1                   அகளவிரித்து               அகலவிரித்து  வேற்றெழுத்து\n2      அணைத்து ஊழியர்களுக்குமான  அனைத்து ஊழியர்களுக்குமான  வேற்றெழுத்து\n3               அதள பாதாளதுக்கு         அதல பாதாளத்துக்கு  வேற்றெழுத்து\n4           அதற்குறிய தீர்வுகளை       அதற்குரிய தீர்வுகளை  வேற்றெழுத்து\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"print(df_cleaned.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:15:08.123978Z","iopub.execute_input":"2025-03-13T18:15:08.124392Z","iopub.status.idle":"2025-03-13T18:15:08.129612Z","shell.execute_reply.started":"2025-03-13T18:15:08.124358Z","shell.execute_reply":"2025-03-13T18:15:08.128784Z"}},"outputs":[{"name":"stdout","text":"Index(['Error word & consecutive word', 'Corrected words & its', 'Annotation'], dtype='object')\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from transformers import MBart50Tokenizer\nimport pandas as pd\n\n# Load tokenizer\ntokenizer = MBart50Tokenizer.from_pretrained('facebook/mbart-large-50-many-to-one-mmt')\n\n# Load your cleaned dataset\ndf_cleaned = pd.read_csv(\"cleaned_dataset.csv\")\n\n# Calculate max input length and max target length based on tokenized sentences\nmax_input_length = max([len(tokenizer.encode(sentence, truncation=True, padding=False)) for sentence in df_cleaned['Error word & consecutive word']])\nmax_target_length = max([len(tokenizer.encode(sentence, truncation=True, padding=False)) for sentence in df_cleaned['Corrected words & its']])\n\nprint(f\"Max Input Length: {max_input_length}\")\nprint(f\"Max Target Length: {max_target_length}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:15:10.173885Z","iopub.execute_input":"2025-03-13T18:15:10.174205Z","iopub.status.idle":"2025-03-13T18:15:18.707112Z","shell.execute_reply.started":"2025-03-13T18:15:10.174181Z","shell.execute_reply":"2025-03-13T18:15:18.706110Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/461 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ab878d473264df0b411e0ad8b0a4a40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"093f71d43de34a028168bc3182111b3a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5815918e3a5a4f3e9eff31bdbdec3815"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.51k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28447fae5dd74092b152c0c1bc4a3417"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"name":"stdout","text":"Max Input Length: 16\nMax Target Length: 26\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_MODE\"] = \"disabled\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:15:20.844774Z","iopub.execute_input":"2025-03-13T18:15:20.845074Z","iopub.status.idle":"2025-03-13T18:15:20.848848Z","shell.execute_reply.started":"2025-03-13T18:15:20.845054Z","shell.execute_reply":"2025-03-13T18:15:20.847988Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import BartTokenizer, EncoderDecoderModel, Trainer, TrainingArguments\nfrom sklearn.model_selection import train_test_split\nfrom datasets import Dataset\n\n\n# Load the cleaned dataset\ndf_cleaned = pd.read_csv(\"cleaned_dataset.csv\")\n\n# Split the dataset into training and validation sets\ntrain_df, val_df = train_test_split(df_cleaned, test_size=0.1)\n\n# Convert the dataframe to Hugging Face dataset format\ntrain_dataset = Dataset.from_pandas(train_df)\nval_dataset = Dataset.from_pandas(val_df)\nfrom transformers import MBart50Tokenizer, MBartForConditionalGeneration\n\n# Load model and tokenizer\nmodel_name = \"facebook/mbart-large-50-many-to-one-mmt\"  # Example multilingual model\ntokenizer = MBart50Tokenizer.from_pretrained(model_name)\nmodel = MBartForConditionalGeneration.from_pretrained(model_name)\n\n# Set the decoder_start_token_id\nmodel.config.decoder_start_token_id = tokenizer.pad_token_id  # You can also use tokenizer.bos_token_id if available\nmodel.config.pad_token_id = tokenizer.pad_token_id \n# Set the output_hidden_states flag to True\n\n\n\n# Tokenizer function\ndef preprocess_function(examples):\n    inputs = examples['Error word & consecutive word']\n    targets = examples['Corrected words & its']\n    \n    # Tokenize the sentences (input and target)\n    model_inputs = tokenizer(inputs, max_length=16, truncation=True, padding=\"max_length\")\n    labels = tokenizer(targets, max_length=26, truncation=True, padding=\"max_length\")\n    \n    # Add the labels to the model inputs\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    \n    return model_inputs\n\n# Apply tokenization on train and validation datasets\ntrain_dataset = train_dataset.map(preprocess_function, batched=True)\nval_dataset = val_dataset.map(preprocess_function, batched=True)\n\n# Set up training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",          # Output directory\n    eval_strategy=\"epoch\",           # Evaluation after each epoch\n    learning_rate=5e-5,              # Learning rate\n    per_device_train_batch_size=16,   # Batch size for training\n    per_device_eval_batch_size=16,    # Batch size for evaluation\n    num_train_epochs=10,              # Number of training epochs\n    weight_decay=0.01,               # Weight decay to avoid overfitting\n    save_total_limit=2,              # Limit on the number of saved checkpoints\n    logging_dir=\"./logs\",\n    warmup_steps=int(0.1 * len(train_dataset)),\n    lr_scheduler_type=\"linear\",\n    gradient_accumulation_steps=2,\n    max_grad_norm=1.0,\n    run_name=\"tamil-error-correction\",\n    report_to=[]\n    # Specify a unique run name\n)\n\n# Create Trainer with WandB tracking\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=tokenizer,  # Make sure the tokenizer is passed for padding, truncation\n    data_collator=None,\n)\n\n# Train the model\ntrainer.train()\n\n# Save the trained model\ntrainer.save_model(\"trained_model\")\n\n# Optionally, evaluate the model on validation set\nresults = trainer.evaluate(val_dataset)\nprint(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:15:27.330054Z","iopub.execute_input":"2025-03-13T18:15:27.330449Z","iopub.status.idle":"2025-03-13T18:43:55.412468Z","shell.execute_reply.started":"2025-03-13T18:15:27.330417Z","shell.execute_reply":"2025-03-13T18:43:55.411316Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6446978a87904677a3fff022f917ca52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/268 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0f20197360f4ee7a285a3de8d997c63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4510 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"807c32efe4594e7d97cbc4b7c86cbaec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/502 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a30d56c5d3444ac2bd5d9e856d1d70e7"}},"metadata":{}},{"name":"stderr","text":"<ipython-input-6-699378fcca65>:69: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='700' max='700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [700/700 27:32, Epoch 9/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>7.561699</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>2.958989</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.214509</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.161179</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.150704</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>0.149278</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>No log</td>\n      <td>0.146126</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>2.286600</td>\n      <td>0.148623</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>2.286600</td>\n      <td>0.152176</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'num_beams': 5, 'forced_bos_token_id': 250004}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [16/16 00:06]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.1521761417388916, 'eval_runtime': 7.0475, 'eval_samples_per_second': 71.231, 'eval_steps_per_second': 2.27, 'epoch': 9.865248226950355}\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import torch\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom nltk.translate.bleu_score import sentence_bleu\n\n\n# Check if GPU is available and move the model to GPU if it is\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = model.to(device)\n\n# Generate predictions on the validation set\npredictions = []\nreferences = []\n\n# Use the model to generate predictions on the validation set\nfor example in val_dataset:\n    input_ids = tokenizer(example['Error word & consecutive word'], return_tensors='pt', padding=True, truncation=True, max_length=35).input_ids\n    \n    # Move input_ids to the correct device (same as the model)\n    input_ids = input_ids.to(device)\n    \n    output_ids = model.generate(input_ids)\n    decoded_prediction = tokenizer.decode(output_ids[0], skip_special_tokens=True)  # Use tokenizer's decode method\n\n    predictions.append(decoded_prediction)\n    references.append(example['Corrected words & its'])\n\n# BLEU Score Calculation (with n-gram overlap)\ndef calculate_bleu(predictions, references):\n    bleu_scores = []\n    for pred, ref in zip(predictions, references):\n        # Tokenize sentences and calculate BLEU score\n        pred_tokens = pred.split()\n        ref_tokens = ref.split()\n        bleu_scores.append(sentence_bleu([ref_tokens], pred_tokens))  # List of references is passed to sentence_bleu\n    return sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0\n\n\n# Calculate BLEU\nbleu_score = calculate_bleu(predictions, references)\n\n\n# Print the results\nprint(f\"BLEU Score: {bleu_score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:47:47.643583Z","iopub.execute_input":"2025-03-13T18:47:47.643922Z","iopub.status.idle":"2025-03-13T18:50:55.697227Z","shell.execute_reply.started":"2025-03-13T18:47:47.643896Z","shell.execute_reply":"2025-03-13T18:50:55.696140Z"}},"outputs":[{"name":"stdout","text":"BLEU Score: 0.8298\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 3-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 2-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 4-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!pip install bert_score\nfrom bert_score import score\nP, R, F1 = score(predictions, references, lang=\"ta\")  # Adjust the language if necessary (e.g., \"ta\" for Tamil)\n\n# Print BERT scores\nprint(f\"BERT Precision: {P.mean():.4f}\")\nprint(f\"BERT Recall: {R.mean():.4f}\")\nprint(f\"BERT F1 Score: {F1.mean():.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:52:18.716911Z","iopub.execute_input":"2025-03-13T18:52:18.717324Z","iopub.status.idle":"2025-03-13T18:52:32.522504Z","shell.execute_reply.started":"2025-03-13T18:52:18.717282Z","shell.execute_reply":"2025-03-13T18:52:32.521350Z"}},"outputs":[{"name":"stdout","text":"Collecting bert_score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.5.1+cu121)\nRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.2.3)\nRequirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.47.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert_score) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.32.3)\nRequirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.67.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert_score) (3.7.5)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert_score) (24.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2025.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.29.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.4.5)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.4.7)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (3.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2025.1.31)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->bert_score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->bert_score) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->bert_score) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->bert_score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->bert_score) (2024.2.0)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: bert_score\nSuccessfully installed bert_score-0.3.13\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"126b4b5c8fba4b7cbbb278847824b8b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c3298b3fb8b417ba9254ffd15fad0b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e405fdb96a24ce3b2bd0b759fffff88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54bb96c3d8b0483da4cdb1ddd10e520c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c119c7f427445378e25bf24e83e972a"}},"metadata":{}},{"name":"stdout","text":"BERT Precision: 0.9698\nBERT Recall: 0.9709\nBERT F1 Score: 0.9703\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import nltk\n\ndef calculate_ter(references, predictions):\n    \"\"\"\n    Compute TER (Translation Edit Rate) score.\n    references: list of reference sentences (the correct sentences)\n    predictions: list of generated sentences (the sentences predicted by the model)\n    \"\"\"\n    # Initialize the TER scores\n    ter_scores = []\n    \n    # Loop over all the sentences\n    for ref, hyp in zip(references, predictions):\n        ref_tokens = ref.split()  # Tokenize the reference sentence\n        hyp_tokens = hyp.split()  # Tokenize the hypothesis sentence\n\n        # Find the minimum edit distance (substitutions, insertions, deletions)\n        edits = nltk.edit_distance(ref_tokens, hyp_tokens)\n\n        # TER is calculated as (number of edits + len(reference) - len(hypothesis)) / len(reference)\n        ter = (edits + len(ref_tokens) - len(hyp_tokens)) / len(ref_tokens)\n        ter_scores.append(ter)\n\n    # Average TER score across all sentences\n    avg_ter = sum(ter_scores) / len(ter_scores) if ter_scores else 0\n    return avg_ter\n\n\n\nter_score = calculate_ter(references, predictions)\nprint(f\"TER Score: {ter_score:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:52:38.618064Z","iopub.execute_input":"2025-03-13T18:52:38.618404Z","iopub.status.idle":"2025-03-13T18:52:38.629419Z","shell.execute_reply.started":"2025-03-13T18:52:38.618377Z","shell.execute_reply":"2025-03-13T18:52:38.628154Z"}},"outputs":[{"name":"stdout","text":"TER Score: 0.2510\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import nltk\nfrom collections import Counter\n\ndef calculate_gleu(references, predictions, max_order=4):\n    \"\"\"\n    Compute GLEU score.\n    references: list of reference sentences (the correct sentences)\n    predictions: list of generated sentences (the sentences predicted by the model)\n    max_order: maximum n-gram length for the BLEU calculation (default is 4)\n    \"\"\"\n    def get_ngrams(tokens, n):\n        return [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n\n    def compute_sentence_gleu(ref_tokens, hyp_tokens):\n        \"\"\"\n        Compute the GLEU score for a single sentence pair.\n        \"\"\"\n        total_ref_ngrams = Counter()\n        total_hyp_ngrams = Counter()\n        total_match_ngrams = Counter()\n\n        for n in range(1, max_order + 1):\n            ref_ngrams = get_ngrams(ref_tokens, n)\n            hyp_ngrams = get_ngrams(hyp_tokens, n)\n            \n            ref_ngrams_count = Counter(ref_ngrams)\n            hyp_ngrams_count = Counter(hyp_ngrams)\n\n            total_ref_ngrams.update(ref_ngrams_count)\n            total_hyp_ngrams.update(hyp_ngrams_count)\n            total_match_ngrams.update(ref_ngrams_count & hyp_ngrams_count)  # Intersection for matching n-grams\n\n        # Compute precision and recall\n        precision = sum(total_match_ngrams.values()) / sum(total_hyp_ngrams.values()) if total_hyp_ngrams else 0\n        recall = sum(total_match_ngrams.values()) / sum(total_ref_ngrams.values()) if total_ref_ngrams else 0\n\n        # Compute GLEU score (harmonic mean of precision and recall)\n        if precision + recall > 0:\n            gleu = (1 + 0.5) * (precision * recall) / (0.5 * precision + recall)\n        else:\n            gleu = 0\n        return gleu\n\n    # Initialize the GLEU scores\n    gleu_scores = []\n\n    # Loop over all reference-prediction pairs\n    for ref, hyp in zip(references, predictions):\n        ref_tokens = ref.split()  # Tokenize the reference sentence\n        hyp_tokens = hyp.split()  # Tokenize the hypothesis sentence\n\n        gleu_score = compute_sentence_gleu(ref_tokens, hyp_tokens)\n        gleu_scores.append(gleu_score)\n\n    # Average GLEU score across all sentences\n    avg_gleu = sum(gleu_scores) / len(gleu_scores) if gleu_scores else 0\n    return avg_gleu\n\ngleu_score = calculate_gleu(references, predictions)\nprint(f\"GLEU Score: {gleu_score:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:52:44.722384Z","iopub.execute_input":"2025-03-13T18:52:44.722715Z","iopub.status.idle":"2025-03-13T18:52:44.754343Z","shell.execute_reply.started":"2025-03-13T18:52:44.722691Z","shell.execute_reply":"2025-03-13T18:52:44.753074Z"}},"outputs":[{"name":"stdout","text":"GLEU Score: 0.7074\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"print(type(val_dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:52:49.655105Z","iopub.execute_input":"2025-03-13T18:52:49.655467Z","iopub.status.idle":"2025-03-13T18:52:49.660924Z","shell.execute_reply.started":"2025-03-13T18:52:49.655439Z","shell.execute_reply":"2025-03-13T18:52:49.659656Z"}},"outputs":[{"name":"stdout","text":"<class 'datasets.arrow_dataset.Dataset'>\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import torch\nimport nltk\nfrom nltk.translate.bleu_score import sentence_bleu\n\n# Ensure nltk package is ready\nnltk.download('punkt')\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Define Tamil samples with similar errors\ntamil_samples = [\n    # 5-word sentences (5 samples)\n    {\"incorrect\": \"வாக்காளர் வழங்கப்பட்டது அரசு அறிவிப்பு\", \"corrected\": \"வாக்காளர்களுக்கு வழங்கப்பட்டது அரசு அறிவிப்பு\"},\n    {\"incorrect\": \"அறிவியல் தொழில்நுட்பம் வளர்ச்சி முக்கியம்\", \"corrected\": \"அறிவியல் மற்றும் தொழில்நுட்ப வளர்ச்சி முக்கியம்\"},\n    {\"incorrect\": \"அன்பு பாராட்டு செய்தார் மக்கள் முன்னிலையில்\", \"corrected\": \"அன்புப் பாராட்டு செய்தார் மக்கள் முன்னிலையில்\"},\n    {\"incorrect\": \"அவசர நடவடிக்க எடுக்க வேண்டும்\", \"corrected\": \"அவசர நடவடிக்கை எடுக்க வேண்டும்\"},\n    {\"incorrect\": \"நடிகர் பேசினார் ரசிகர்கள் கூட்டத்தில்\", \"corrected\": \"நடிகர் பேசினார் ரசிகர்கள் கூட்டத்தில்\"},\n\n    # 4-word sentences (8 samples)\n    {\"incorrect\": \"மழை காரணம் வெள்ளம் ஏற்பட்டது\", \"corrected\": \"மழை காரணமாக வெள்ளம் ஏற்பட்டது\"},\n    {\"incorrect\": \"நாடு முன்னேற்ற வளர்ச்சி இன்றியமையாது\", \"corrected\": \"நாடு முன்னேற்றம் வளர்ச்சி இன்றியமையாது\"},\n    {\"incorrect\": \"சுற்றுச்சூழல் பாதுகாப்பு மிக முக்கியம்\", \"corrected\": \"சுற்றுச்சூழல் பாதுகாப்பு மிக முக்கியம்\"},\n    {\"incorrect\": \"அவன் விரைவில் சென்று விட்டான்\", \"corrected\": \"அவன் விரைவாக சென்று விட்டான்\"},\n    {\"incorrect\": \"படிப்பு முடித்த வேலை பெற்றான்\", \"corrected\": \"படிப்பு முடித்து வேலை பெற்றான்\"},\n    {\"incorrect\": \"நேரம் செலவழிக்க மிக முக்கியம்\", \"corrected\": \"நேரம் செலவழிக்க மிக முக்கியம்\"},\n    {\"incorrect\": \"மகிழ்ச்சி உணர்வு மனதை உற்சாகம்\", \"corrected\": \"மகிழ்ச்சி உணர்வு மனதை உற்சாகம்\"},\n    {\"incorrect\": \"மழை காலநிலை கடுமையாக உள்ளது\", \"corrected\": \"மழைக்கால நிலை கடுமையாக உள்ளது\"},\n\n    # 3-word sentences (2 samples)\n    {\"incorrect\": \"நான் பெற்ற மதிப்பெண்\", \"corrected\": \"நான் பெற்ற மதிப்பெண்கள்\"},\n    {\"incorrect\": \"சிறந்த இசை பாடல்\", \"corrected\": \"சிறந்த இசைப் பாடல்\"},\n]\n\n\ntotal_bleu_score = 0.0  # Store cumulative BLEU score\nnum_samples = len(tamil_samples)\n\nfor sample in tamil_samples:\n    incorrect_sentence = sample[\"incorrect\"]\n    corrected_sentence = sample[\"corrected\"]\n\n    # Tokenize the incorrect sentence\n    inputs = tokenizer(incorrect_sentence, return_tensors=\"pt\")\n\n    # Move inputs to the same device as the model (GPU if available)\n    inputs = {key: value.to(device) for key, value in inputs.items()}\n\n    # Generate the predicted sentence\n    with torch.no_grad():\n        outputs = model.generate(\n            input_ids=inputs[\"input_ids\"],\n            max_length=50,\n            num_beams=5,  \n            temperature=0.7,  \n            top_k=50, \n            top_p=0.9,\n            early_stopping=True\n        )\n\n    # Decode the predicted sentence\n    predicted_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n    # Compute BLEU score\n    reference = [nltk.word_tokenize(corrected_sentence)]\n    candidate = nltk.word_tokenize(predicted_sentence)\n\n    bleu_score = sentence_bleu(reference, candidate, weights=(0.5, 0.5))  # Bi-gram BLEU score\n    total_bleu_score += bleu_score\n\n    # Print results\n    print(\"\\nIncorrect Sentence:\", incorrect_sentence)\n    print(\"Corrected Sentence:\", corrected_sentence)\n    print(\"Predicted Sentence:\", predicted_sentence)\n    print(\"BLEU Score: {:.2f}\".format(bleu_score))\n\n# Compute the average BLEU score\naverage_bleu_score = total_bleu_score / num_samples\nprint(\"\\nAverage BLEU Score: {:.2f}\".format(average_bleu_score))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:52:54.754411Z","iopub.execute_input":"2025-03-13T18:52:54.754776Z","iopub.status.idle":"2025-03-13T18:52:58.690600Z","shell.execute_reply.started":"2025-03-13T18:52:54.754747Z","shell.execute_reply":"2025-03-13T18:52:58.689543Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nIncorrect Sentence: வாக்காளர் வழங்கப்பட்டது அரசு அறிவிப்பு\nCorrected Sentence: வாக்காளர்களுக்கு வழங்கப்பட்டது அரசு அறிவிப்பு\nPredicted Sentence: வாக்காளர் வழங்கப்பட்டது அரசு அறிவிப்பு\nBLEU Score: 0.71\n\nIncorrect Sentence: அறிவியல் தொழில்நுட்பம் வளர்ச்சி முக்கியம்\nCorrected Sentence: அறிவியல் மற்றும் தொழில்நுட்ப வளர்ச்சி முக்கியம்\nPredicted Sentence: அறிவியல்த் தொழில்நுட்பம் வளர்ச்சி முக்கியம்\nBLEU Score: 0.32\n\nIncorrect Sentence: அன்பு பாராட்டு செய்தார் மக்கள் முன்னிலையில்\nCorrected Sentence: அன்புப் பாராட்டு செய்தார் மக்கள் முன்னிலையில்\nPredicted Sentence: அன்புப் பாராட்டு செய்தார் மக்கள் முன்னிலையில்\nBLEU Score: 1.00\n\nIncorrect Sentence: அவசர நடவடிக்க எடுக்க வேண்டும்\nCorrected Sentence: அவசர நடவடிக்கை எடுக்க வேண்டும்\nPredicted Sentence: அவசர நடவடிக்க எடுக்க வேண்டும்\nBLEU Score: 0.50\n\nIncorrect Sentence: நடிகர் பேசினார் ரசிகர்கள் கூட்டத்தில்\nCorrected Sentence: நடிகர் பேசினார் ரசிகர்கள் கூட்டத்தில்\nPredicted Sentence: நடிகர்ப் பேசினார் ரசிகர்கள் கூட்டத்தில்\nBLEU Score: 0.71\n\nIncorrect Sentence: மழை காரணம் வெள்ளம் ஏற்பட்டது\nCorrected Sentence: மழை காரணமாக வெள்ளம் ஏற்பட்டது\nPredicted Sentence: மழைக் காரணம் வெள்ளம் ஏற்பட்டது\nBLEU Score: 0.41\n\nIncorrect Sentence: நாடு முன்னேற்ற வளர்ச்சி இன்றியமையாது\nCorrected Sentence: நாடு முன்னேற்றம் வளர்ச்சி இன்றியமையாது\nPredicted Sentence: நாடு முன்னேற்ற வளர்ச்சி இன்றியமையாது\nBLEU Score: 0.50\n\nIncorrect Sentence: சுற்றுச்சூழல் பாதுகாப்பு மிக முக்கியம்\nCorrected Sentence: சுற்றுச்சூழல் பாதுகாப்பு மிக முக்கியம்\nPredicted Sentence: சுற்றுச்சூழல் பாதுகாப்பு மிக முக்கியம்\nBLEU Score: 1.00\n\nIncorrect Sentence: அவன் விரைவில் சென்று விட்டான்\nCorrected Sentence: அவன் விரைவாக சென்று விட்டான்\nPredicted Sentence: அவன் விரைவில்ச் சென்று விட்டான்\nBLEU Score: 0.50\n\nIncorrect Sentence: படிப்பு முடித்த வேலை பெற்றான்\nCorrected Sentence: படிப்பு முடித்து வேலை பெற்றான்\nPredicted Sentence: படிப்பு முடித்த வேலை பெற்றான்\nBLEU Score: 0.50\n\nIncorrect Sentence: நேரம் செலவழிக்க மிக முக்கியம்\nCorrected Sentence: நேரம் செலவழிக்க மிக முக்கியம்\nPredicted Sentence: நேரம்ச் செலவழிக்க மிக முக்கியம்\nBLEU Score: 0.71\n\nIncorrect Sentence: மகிழ்ச்சி உணர்வு மனதை உற்சாகம்\nCorrected Sentence: மகிழ்ச்சி உணர்வு மனதை உற்சாகம்\nPredicted Sentence: happinessத் உணர்வு மனதை உற்சாகம்\nBLEU Score: 0.71\n\nIncorrect Sentence: மழை காலநிலை கடுமையாக உள்ளது\nCorrected Sentence: மழைக்கால நிலை கடுமையாக உள்ளது\nPredicted Sentence: மழைக் காலநிலை கடுமையாக உள்ளது\nBLEU Score: 0.41\n\nIncorrect Sentence: நான் பெற்ற மதிப்பெண்\nCorrected Sentence: நான் பெற்ற மதிப்பெண்கள்\nPredicted Sentence: நான் பெற்ற மதிப்பெண்\nBLEU Score: 0.58\n\nIncorrect Sentence: சிறந்த இசை பாடல்\nCorrected Sentence: சிறந்த இசைப் பாடல்\nPredicted Sentence: சிறந்தச் இசை பாடல்\nBLEU Score: 0.58\n\nAverage BLEU Score: 0.61\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"!pip install sacrebleu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:53:28.827134Z","iopub.execute_input":"2025-03-13T18:53:28.827487Z","iopub.status.idle":"2025-03-13T18:53:33.726977Z","shell.execute_reply.started":"2025-03-13T18:53:28.827461Z","shell.execute_reply":"2025-03-13T18:53:33.725287Z"}},"outputs":[{"name":"stdout","text":"Collecting sacrebleu\n  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.11.6)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (5.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->sacrebleu) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-3.1.1 sacrebleu-2.5.1\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import torch\nimport nltk\nimport sacrebleu\nfrom nltk.translate.bleu_score import sentence_bleu\nfrom nltk.translate.gleu_score import sentence_gleu  # Import for GLEU\n\n# Ensure nltk package is ready\nnltk.download('punkt')\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Define Tamil samples with similar errors\ntamil_samples = [\n    # 5-word sentences (5 samples)\n    {\"incorrect\": \"வாக்காளர் வழங்கப்பட்டது அரசு அறிவிப்பு\", \"corrected\": \"வாக்காளர்களுக்கு வழங்கப்பட்டது அரசு அறிவிப்பு\"},\n    {\"incorrect\": \"அன்பு பாராட்டு செய்தார் மக்கள் முன்னிலையில்\", \"corrected\": \"அன்புப் பாராட்டு செய்தார் மக்கள் முன்னிலையில்\"},\n    {\"incorrect\": \"அவசர நடவடிக்க எடுக்க வேண்டும்\", \"corrected\": \"அவசர நடவடிக்கை எடுக்க வேண்டும்\"},\n    {\"incorrect\": \"நடிகர் பேசினார் ரசிகர்கள் கூட்டத்தில்\", \"corrected\": \"நடிகர் பேசினார் ரசிகர்கள் கூட்டத்தில்\"},\n\n    # 4-word sentences (8 samples)\n    {\"incorrect\": \"நாடு முன்னேற்ற வளர்ச்சி இன்றியமையாது\", \"corrected\": \"நாடு முன்னேற்றம் வளர்ச்சி இன்றியமையாது\"},\n    {\"incorrect\": \"சுற்றுச்சூழல் பாதுகாப்பு மிக முக்கியம்\", \"corrected\": \"சுற்றுச்சூழல் பாதுகாப்பு மிக முக்கியம்\"},\n    {\"incorrect\": \"நேரம் செலவழிக்க மிக முக்கியம்\", \"corrected\": \"நேரம் செலவழிக்க மிக முக்கியம்\"},\n    {\"incorrect\": \"மகிழ்ச்சி உணர்வு மனதை உற்சாகம்\", \"corrected\": \"மகிழ்ச்சி உணர்வு மனதை உற்சாகம்\"},\n\n\n    # 3-word sentences (2 samples)\n    {\"incorrect\": \"சிறந்த இசை பாடல்\", \"corrected\": \"சிறந்த இசைப் பாடல்\"},\n]\n\ntotal_bleu_score = 0.0\ntotal_gleu_score = 0.0\nreferences = []  # Store references for TER\nhypotheses = []  # Store hypotheses for TER\n\nnum_samples = len(tamil_samples)\n\nfor sample in tamil_samples:\n    incorrect_sentence = sample[\"incorrect\"]\n    corrected_sentence = sample[\"corrected\"]\n\n    # Tokenize the incorrect sentence\n    inputs = tokenizer(incorrect_sentence, return_tensors=\"pt\")\n\n    # Move inputs to the same device as the model (GPU if available)\n    inputs = {key: value.to(device) for key, value in inputs.items()}\n\n    # Generate the predicted sentence\n    with torch.no_grad():\n        outputs = model.generate(\n            input_ids=inputs[\"input_ids\"],\n            max_length=50,\n            num_beams=5,  \n            temperature=0.7,  \n            top_k=50, \n            top_p=0.9,\n            early_stopping=True\n        )\n\n    # Decode the predicted sentence\n    predicted_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n    # Compute BLEU score\n    reference = [nltk.word_tokenize(corrected_sentence)]\n    candidate = nltk.word_tokenize(predicted_sentence)\n    bleu_score = sentence_bleu(reference, candidate, weights=(0.5, 0.5))  # Bi-gram BLEU score\n    total_bleu_score += bleu_score\n\n    # Compute GLEU score\n    gleu_score = sentence_gleu(reference, candidate)\n    total_gleu_score += gleu_score\n\n    # Store sentences for TER calculation\n    references.append([corrected_sentence])\n    hypotheses.append(predicted_sentence)\n\n    # Print results\n    print(\"\\nIncorrect Sentence:\", incorrect_sentence)\n    print(\"Corrected Sentence:\", corrected_sentence)\n    print(\"Predicted Sentence:\", predicted_sentence)\n    print(\"BLEU Score: {:.2f}\".format(bleu_score))\n    print(\"GLEU Score: {:.2f}\".format(gleu_score))\n\n# Compute the average BLEU and GLEU scores\naverage_bleu_score = total_bleu_score / num_samples\naverage_gleu_score = total_gleu_score / num_samples\n\n# Compute TER score\nter_score = sacrebleu.corpus_ter(hypotheses, references).score\n\nprint(\"\\nAverage BLEU Score: {:.2f}\".format(average_bleu_score))\nprint(\"Average GLEU Score: {:.2f}\".format(average_gleu_score))\nprint(\"TER Score: {:.2f}\".format(ter_score))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:56:04.430753Z","iopub.execute_input":"2025-03-13T18:56:04.431305Z","iopub.status.idle":"2025-03-13T18:56:06.594811Z","shell.execute_reply.started":"2025-03-13T18:56:04.431267Z","shell.execute_reply":"2025-03-13T18:56:06.593694Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n\nIncorrect Sentence: வாக்காளர் வழங்கப்பட்டது அரசு அறிவிப்பு\nCorrected Sentence: வாக்காளர்களுக்கு வழங்கப்பட்டது அரசு அறிவிப்பு\nPredicted Sentence: வாக்காளர் வழங்கப்பட்டது அரசு அறிவிப்பு\nBLEU Score: 0.71\nGLEU Score: 0.60\n\nIncorrect Sentence: அன்பு பாராட்டு செய்தார் மக்கள் முன்னிலையில்\nCorrected Sentence: அன்புப் பாராட்டு செய்தார் மக்கள் முன்னிலையில்\nPredicted Sentence: அன்புப் பாராட்டு செய்தார் மக்கள் முன்னிலையில்\nBLEU Score: 1.00\nGLEU Score: 1.00\n\nIncorrect Sentence: அவசர நடவடிக்க எடுக்க வேண்டும்\nCorrected Sentence: அவசர நடவடிக்கை எடுக்க வேண்டும்\nPredicted Sentence: அவசர நடவடிக்க எடுக்க வேண்டும்\nBLEU Score: 0.50\nGLEU Score: 0.40\n\nIncorrect Sentence: நடிகர் பேசினார் ரசிகர்கள் கூட்டத்தில்\nCorrected Sentence: நடிகர் பேசினார் ரசிகர்கள் கூட்டத்தில்\nPredicted Sentence: நடிகர்ப் பேசினார் ரசிகர்கள் கூட்டத்தில்\nBLEU Score: 0.71\nGLEU Score: 0.60\n\nIncorrect Sentence: நாடு முன்னேற்ற வளர்ச்சி இன்றியமையாது\nCorrected Sentence: நாடு முன்னேற்றம் வளர்ச்சி இன்றியமையாது\nPredicted Sentence: நாடு முன்னேற்ற வளர்ச்சி இன்றியமையாது\nBLEU Score: 0.50\nGLEU Score: 0.40\n\nIncorrect Sentence: சுற்றுச்சூழல் பாதுகாப்பு மிக முக்கியம்\nCorrected Sentence: சுற்றுச்சூழல் பாதுகாப்பு மிக முக்கியம்\nPredicted Sentence: சுற்றுச்சூழல் பாதுகாப்பு மிக முக்கியம்\nBLEU Score: 1.00\nGLEU Score: 1.00\n\nIncorrect Sentence: நேரம் செலவழிக்க மிக முக்கியம்\nCorrected Sentence: நேரம் செலவழிக்க மிக முக்கியம்\nPredicted Sentence: நேரம்ச் செலவழிக்க மிக முக்கியம்\nBLEU Score: 0.71\nGLEU Score: 0.60\n\nIncorrect Sentence: மகிழ்ச்சி உணர்வு மனதை உற்சாகம்\nCorrected Sentence: மகிழ்ச்சி உணர்வு மனதை உற்சாகம்\nPredicted Sentence: happinessத் உணர்வு மனதை உற்சாகம்\nBLEU Score: 0.71\nGLEU Score: 0.60\n\nIncorrect Sentence: சிறந்த இசை பாடல்\nCorrected Sentence: சிறந்த இசைப் பாடல்\nPredicted Sentence: சிறந்தச் இசை பாடல்\nBLEU Score: 0.58\nGLEU Score: 0.17\n\nAverage BLEU Score: 0.71\nAverage GLEU Score: 0.60\nTER Score: 25.00\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Extract logs from Trainer state\nlog_history = trainer.state.log_history\n\n# Separate training and validation losses\ntrain_losses = [entry['loss'] for entry in log_history if 'loss' in entry]\neval_losses = [entry['eval_loss'] for entry in log_history if 'eval_loss' in entry]\nlearning_rates = [entry['learning_rate'] for entry in log_history if 'learning_rate' in entry]\n\n# Create x-axis for epochs\n\nepochs_eval = range(1, len(eval_losses) + 1)\n\n\n# Plot validation loss\nplt.figure(figsize=(6, 4))\nplt.plot(epochs_eval, eval_losses, label=\"Validation Loss\", marker='o', color='red')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Validation Loss over Epochs\")\nplt.legend()\nplt.grid()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:58:08.117689Z","iopub.execute_input":"2025-03-13T18:58:08.118160Z","iopub.status.idle":"2025-03-13T18:58:08.532654Z","shell.execute_reply.started":"2025-03-13T18:58:08.118127Z","shell.execute_reply":"2025-03-13T18:58:08.531651Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 600x400 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":18}]}